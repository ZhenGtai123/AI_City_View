{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Intelligent Foreground-Middleground-Background Segmentation System - Complete Version\n",
        "\n",
        "This system integrates:\n",
        "1. Theory-based initial partitioning\n",
        "2. K-means boundary optimization\n",
        "3. Intelligent connectivity processing\n",
        "4. Multi-strategy layer decision\n",
        "5. Intelligent hole filling post-processing\n",
        "6. Forced semantic rules (e.g., sky is always background)\n",
        "\n",
        "Author: Kai\n",
        "Version: 2.1 (Updated with forced semantic rules)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy import ndimage\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Colab compatibility check\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Note: Not in Google Colab environment, file upload functionality will be skipped\")\n",
        "\n",
        "# ==================== Data Structure Definitions ====================\n",
        "\n",
        "@dataclass\n",
        "class ObjectFeatures:\n",
        "    \"\"\"Comprehensive feature description of an object\"\"\"\n",
        "    # Basic attributes\n",
        "    num_pixels: int\n",
        "    semantic_class: int\n",
        "    is_closed: bool\n",
        "    is_countable: bool\n",
        "\n",
        "    # Shape features\n",
        "    effective_aspect_ratio: float\n",
        "    bbox_aspect_ratio: float\n",
        "    compactness: float\n",
        "    elongation: float\n",
        "\n",
        "    # Depth features\n",
        "    depth_mean: float\n",
        "    depth_std: float\n",
        "    depth_range: float\n",
        "    vertical_depth_gradient: float\n",
        "    horizontal_depth_gradient: float\n",
        "\n",
        "    # Spatial position\n",
        "    centroid_y: float\n",
        "    centroid_x: float\n",
        "    bottom_y: int\n",
        "    relative_y_position: float\n",
        "\n",
        "    # Neighborhood relationships\n",
        "    touching_ground: bool\n",
        "    touching_sky: bool\n",
        "    neighbor_classes: List[int]\n",
        "\n",
        "    # Texture and structure\n",
        "    edge_density: float\n",
        "    internal_structure_complexity: float\n",
        "\n",
        "# ==================== Forced Semantic Rules ====================\n",
        "\n",
        "class ForcedSemanticRules:\n",
        "    \"\"\"\n",
        "    Forced Semantic Rules System\n",
        "    \n",
        "    This class defines semantic categories that should ALWAYS be assigned\n",
        "    to specific layers, regardless of depth or other analysis.\n",
        "    \n",
        "    For example: Sky is ALWAYS background.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, idx_to_info: Dict):\n",
        "        self.idx_to_info = idx_to_info\n",
        "        self.forced_background_classes = []\n",
        "        self.forced_foreground_classes = []\n",
        "        self.forced_middleground_classes = []\n",
        "        \n",
        "        self._initialize_forced_rules()\n",
        "    \n",
        "    def _initialize_forced_rules(self):\n",
        "        \"\"\"Initialize forced semantic rules based on class names\"\"\"\n",
        "        for idx, info in self.idx_to_info.items():\n",
        "            name = info['name'].lower()\n",
        "            \n",
        "            # SKY is ALWAYS BACKGROUND - this is a forced rule\n",
        "            if 'sky' in name:\n",
        "                self.forced_background_classes.append(idx)\n",
        "                print(f\"  [Forced Rule] Class '{info['name']}' (idx={idx}) -> ALWAYS BACKGROUND\")\n",
        "            \n",
        "            # Sea/ocean is always background\n",
        "            elif 'sea' in name and 'seat' not in name:\n",
        "                self.forced_background_classes.append(idx)\n",
        "                print(f\"  [Forced Rule] Class '{info['name']}' (idx={idx}) -> ALWAYS BACKGROUND\")\n",
        "    \n",
        "    def get_forced_layer(self, semantic_class: int) -> Optional[int]:\n",
        "        if semantic_class in self.forced_background_classes:\n",
        "            return 2\n",
        "        elif semantic_class in self.forced_foreground_classes:\n",
        "            return 0\n",
        "        elif semantic_class in self.forced_middleground_classes:\n",
        "            return 1\n",
        "        return None\n",
        "    \n",
        "    def is_forced(self, semantic_class: int) -> bool:\n",
        "        return self.get_forced_layer(semantic_class) is not None\n",
        "\n",
        "\n",
        "# ==================== Intelligent Hole Filling System ====================\n",
        "\n",
        "class IntelligentHoleFilling:\n",
        "    \"\"\"Intelligent Hole Filling System\"\"\"\n",
        "\n",
        "    min_hole_size = 10\n",
        "    max_hole_size = 5000\n",
        "    depth_threshold_ratio = 0.15\n",
        "\n",
        "    def __init__(self, depth_map: np.ndarray, fmb_map: np.ndarray):\n",
        "        self.depth_map = depth_map\n",
        "        self.fmb_map = fmb_map\n",
        "        self.H, self.W = depth_map.shape\n",
        "        self.neighbor_radius = 5\n",
        "\n",
        "    def process(self) -> Tuple[np.ndarray, Dict]:\n",
        "        filled_map = self.fmb_map.copy()\n",
        "        fill_info = {\n",
        "            'total_holes_detected': 0,\n",
        "            'holes_filled': 0,\n",
        "            'holes_preserved': 0,\n",
        "            'details': []\n",
        "        }\n",
        "\n",
        "        for layer in [0, 1, 2]:\n",
        "            layer_name = ['Foreground', 'Middleground', 'Background'][layer]\n",
        "            print(f\"\\nProcessing layer {layer} ({layer_name})...\")\n",
        "\n",
        "            holes = self._detect_holes_in_layer(filled_map, layer)\n",
        "            fill_info['total_holes_detected'] += len(holes)\n",
        "            print(f\"  Detected {len(holes)} holes\")\n",
        "\n",
        "            for hole_id, hole_mask in enumerate(holes):\n",
        "                hole_size = np.sum(hole_mask)\n",
        "\n",
        "                if hole_size < self.min_hole_size or hole_size > self.max_hole_size:\n",
        "                    continue\n",
        "\n",
        "                should_fill, analysis = self._analyze_hole(hole_mask, layer)\n",
        "\n",
        "                if should_fill:\n",
        "                    filled_map[hole_mask] = layer\n",
        "                    fill_info['holes_filled'] += 1\n",
        "                    print(f\"    Hole {hole_id}: Filled (size={hole_size}, depth_diff={analysis['depth_difference']:.2f})\")\n",
        "                else:\n",
        "                    fill_info['holes_preserved'] += 1\n",
        "                    print(f\"    Hole {hole_id}: Preserved (size={hole_size}, depth_diff={analysis['depth_difference']:.2f})\")\n",
        "\n",
        "                fill_info['details'].append({\n",
        "                    'layer': layer, 'hole_id': hole_id, 'size': hole_size,\n",
        "                    'filled': should_fill, 'analysis': analysis\n",
        "                })\n",
        "\n",
        "        print(f\"\\nFilling statistics:\")\n",
        "        print(f\"  Total holes detected: {fill_info['total_holes_detected']}\")\n",
        "        print(f\"  Holes filled: {fill_info['holes_filled']}\")\n",
        "        print(f\"  Holes preserved: {fill_info['holes_preserved']}\")\n",
        "\n",
        "        return filled_map, fill_info\n",
        "\n",
        "    def _detect_holes_in_layer(self, fmb_map: np.ndarray, layer: int) -> List[np.ndarray]:\n",
        "        layer_mask = (fmb_map == layer).astype(np.uint8)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        layer_closed = cv2.morphologyEx(layer_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        layer_filled = self._fill_holes_morphological(layer_closed)\n",
        "        holes_mask = layer_filled & (~layer_mask)\n",
        "        labeled_holes, num_holes = ndimage.label(holes_mask)\n",
        "\n",
        "        holes = []\n",
        "        for hole_id in range(1, num_holes + 1):\n",
        "            hole_mask = labeled_holes == hole_id\n",
        "            if self._is_hole_surrounded(hole_mask, fmb_map, layer):\n",
        "                holes.append(hole_mask)\n",
        "        return holes\n",
        "\n",
        "    def _fill_holes_morphological(self, binary_mask: np.ndarray) -> np.ndarray:\n",
        "        filled = binary_mask.copy()\n",
        "        h, w = binary_mask.shape\n",
        "        mask = np.zeros((h + 2, w + 2), np.uint8)\n",
        "        cv2.floodFill(filled, mask, (0, 0), 1)\n",
        "        filled_inv = cv2.bitwise_not(filled)\n",
        "        result = binary_mask | filled_inv\n",
        "        return result.astype(np.uint8)\n",
        "\n",
        "    def _is_hole_surrounded(self, hole_mask: np.ndarray, fmb_map: np.ndarray, layer: int) -> bool:\n",
        "        dilated = ndimage.binary_dilation(hole_mask, iterations=2)\n",
        "        boundary = dilated & (~hole_mask)\n",
        "        boundary_values = fmb_map[boundary]\n",
        "        unique_values, counts = np.unique(boundary_values, return_counts=True)\n",
        "        target_ratio = 0.0\n",
        "        for val, count in zip(unique_values, counts):\n",
        "            if val == layer:\n",
        "                target_ratio = count / np.sum(counts)\n",
        "                break\n",
        "        return target_ratio > 0.8\n",
        "\n",
        "    def _analyze_hole(self, hole_mask: np.ndarray, surrounding_layer: int) -> Tuple[bool, Dict]:\n",
        "        hole_depths = self.depth_map[hole_mask]\n",
        "        hole_mean_depth = np.mean(hole_depths)\n",
        "        hole_std_depth = np.std(hole_depths)\n",
        "\n",
        "        dilated = ndimage.binary_dilation(hole_mask, iterations=self.neighbor_radius)\n",
        "        neighbor_mask = dilated & (~hole_mask) & (self.fmb_map == surrounding_layer)\n",
        "\n",
        "        if np.sum(neighbor_mask) == 0:\n",
        "            return False, {\n",
        "                'depth_difference': float('inf'),\n",
        "                'hole_mean_depth': hole_mean_depth,\n",
        "                'neighbor_mean_depth': None,\n",
        "                'decision_reason': 'no_valid_neighbors'\n",
        "            }\n",
        "\n",
        "        neighbor_depths = self.depth_map[neighbor_mask]\n",
        "        neighbor_mean_depth = np.mean(neighbor_depths)\n",
        "        neighbor_std_depth = np.std(neighbor_depths)\n",
        "        depth_difference = abs(hole_mean_depth - neighbor_mean_depth)\n",
        "\n",
        "        local_depths = np.concatenate([hole_depths, neighbor_depths])\n",
        "        local_depth_range = np.max(local_depths) - np.min(local_depths)\n",
        "        if local_depth_range < 1:\n",
        "            local_depth_range = 1\n",
        "\n",
        "        normalized_difference = depth_difference / local_depth_range\n",
        "        should_fill = normalized_difference < self.depth_threshold_ratio\n",
        "\n",
        "        if hole_std_depth > neighbor_std_depth * 2:\n",
        "            should_fill = False\n",
        "            decision_reason = 'high_internal_variance'\n",
        "        elif should_fill:\n",
        "            decision_reason = 'small_depth_difference'\n",
        "        else:\n",
        "            decision_reason = 'large_depth_difference'\n",
        "\n",
        "        analysis = {\n",
        "            'depth_difference': depth_difference,\n",
        "            'normalized_difference': normalized_difference,\n",
        "            'hole_mean_depth': hole_mean_depth,\n",
        "            'hole_std_depth': hole_std_depth,\n",
        "            'neighbor_mean_depth': neighbor_mean_depth,\n",
        "            'neighbor_std_depth': neighbor_std_depth,\n",
        "            'local_depth_range': local_depth_range,\n",
        "            'decision_reason': decision_reason\n",
        "        }\n",
        "        return should_fill, analysis\n",
        "\n",
        "# ==================== Intelligent Layer Decision System ====================\n",
        "\n",
        "class IntelligentLayerDecisionSystem:\n",
        "    \"\"\"Intelligent Integrated Layer Decision System\"\"\"\n",
        "\n",
        "    def __init__(self, depth_map, semantic_map, fmb_map, openness, countability, idx_to_info,\n",
        "                 forced_rules: ForcedSemanticRules = None):\n",
        "        self.depth_map = depth_map\n",
        "        self.semantic_map = semantic_map\n",
        "        self.fmb_map = fmb_map\n",
        "        self.openness = openness\n",
        "        self.countability = countability\n",
        "        self.idx_to_info = idx_to_info\n",
        "        self.H, self.W = depth_map.shape\n",
        "        self.forced_rules = forced_rules\n",
        "\n",
        "        self.strategy_weights = {\n",
        "            'bottom_sampling': 0.3,\n",
        "            'horizontal_analysis': 0.3,\n",
        "            'vertical_structure': 0.2,\n",
        "            'spatial_context': 0.1,\n",
        "            'depth_consistency': 0.1\n",
        "        }\n",
        "        self._initialize_semantic_categories()\n",
        "\n",
        "    def _initialize_semantic_categories(self):\n",
        "        \"\"\"Initialize spatial expectations for semantic categories - UPDATED for new config\"\"\"\n",
        "        self.sky_classes = []\n",
        "        self.ground_classes = []\n",
        "        self.tall_classes = []\n",
        "\n",
        "        for idx, info in self.idx_to_info.items():\n",
        "            name = info['name'].lower()\n",
        "            \n",
        "            if 'sky' in name:\n",
        "                self.sky_classes.append(idx)\n",
        "            elif any(word in name for word in [\n",
        "                'road', 'route', 'pavement', 'sidewalk', 'grass', 'ground', 'land', \n",
        "                'floor', 'flooring', 'path', 'sand', 'dirt', 'track', 'runway',\n",
        "                'field', 'earth', 'rug', 'carpet', 'stairway', 'staircase', \n",
        "                'escalator', 'step', 'stair', 'stairs'\n",
        "            ]):\n",
        "                self.ground_classes.append(idx)\n",
        "            elif any(word in name for word in [\n",
        "                'tree', 'building', 'edifice', 'tower', 'pole', 'light', 'lamp',\n",
        "                'palm', 'skyscraper', 'column', 'pillar', 'streetlight', 'chandelier'\n",
        "            ]):\n",
        "                self.tall_classes.append(idx)\n",
        "\n",
        "    def extract_object_features(self, region_mask) -> ObjectFeatures:\n",
        "        \"\"\"Extract comprehensive features of an object\"\"\"\n",
        "        y_coords, x_coords = np.where(region_mask)\n",
        "        if len(y_coords) == 0:\n",
        "            return None\n",
        "\n",
        "        num_pixels = len(y_coords)\n",
        "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
        "        x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
        "\n",
        "        semantic_values = self.semantic_map[region_mask]\n",
        "        semantic_class = np.bincount(semantic_values).argmax()\n",
        "        is_closed = self.openness[semantic_class - 1] == 1 if semantic_class > 0 else False\n",
        "        is_countable = self.countability[semantic_class - 1] == 1 if semantic_class > 0 else False\n",
        "\n",
        "        effective_aspect_ratio = self._calculate_effective_aspect_ratio(region_mask)\n",
        "        bbox_aspect_ratio = (y_max - y_min + 1) / (x_max - x_min + 1)\n",
        "        compactness = num_pixels / ((y_max - y_min + 1) * (x_max - x_min + 1))\n",
        "\n",
        "        if num_pixels > 5:\n",
        "            coords = np.column_stack((x_coords - np.mean(x_coords), y_coords - np.mean(y_coords)))\n",
        "            cov_matrix = np.cov(coords.T)\n",
        "            eigenvalues = np.linalg.eigvalsh(cov_matrix)\n",
        "            elongation = np.sqrt(max(eigenvalues) / (min(eigenvalues) + 1e-6))\n",
        "        else:\n",
        "            elongation = 1.0\n",
        "\n",
        "        depths = self.depth_map[region_mask]\n",
        "        depth_mean = np.mean(depths)\n",
        "        depth_std = np.std(depths)\n",
        "        depth_range = np.max(depths) - np.min(depths)\n",
        "\n",
        "        vertical_gradient = self._calculate_vertical_gradient(region_mask, depths, y_coords)\n",
        "        horizontal_gradient = self._calculate_horizontal_gradient(region_mask, depths, x_coords)\n",
        "\n",
        "        centroid_y = np.mean(y_coords)\n",
        "        centroid_x = np.mean(x_coords)\n",
        "        bottom_y = y_max\n",
        "        relative_y_position = centroid_y / self.H\n",
        "\n",
        "        touching_ground = y_max >= self.H - 5\n",
        "        touching_sky = y_min <= 5\n",
        "        neighbor_classes = self._get_neighbor_classes(region_mask)\n",
        "        edge_density = self._calculate_edge_density(region_mask)\n",
        "        internal_structure = self._calculate_internal_structure(region_mask)\n",
        "\n",
        "        return ObjectFeatures(\n",
        "            num_pixels=num_pixels, semantic_class=semantic_class,\n",
        "            is_closed=is_closed, is_countable=is_countable,\n",
        "            effective_aspect_ratio=effective_aspect_ratio, bbox_aspect_ratio=bbox_aspect_ratio,\n",
        "            compactness=compactness, elongation=elongation,\n",
        "            depth_mean=depth_mean, depth_std=depth_std, depth_range=depth_range,\n",
        "            vertical_depth_gradient=vertical_gradient, horizontal_depth_gradient=horizontal_gradient,\n",
        "            centroid_y=centroid_y, centroid_x=centroid_x, bottom_y=bottom_y,\n",
        "            relative_y_position=relative_y_position,\n",
        "            touching_ground=touching_ground, touching_sky=touching_sky,\n",
        "            neighbor_classes=neighbor_classes,\n",
        "            edge_density=edge_density, internal_structure_complexity=internal_structure\n",
        "        )\n",
        "\n",
        "    def intelligent_layer_decision(self, region_mask) -> Tuple[int, float, Dict]:\n",
        "        \"\"\"Main function for intelligent layer decision\"\"\"\n",
        "        features = self.extract_object_features(region_mask)\n",
        "        if features is None:\n",
        "            return None, 0, {}\n",
        "\n",
        "        # CHECK FORCED RULES FIRST\n",
        "        if self.forced_rules and self.forced_rules.is_forced(features.semantic_class):\n",
        "            forced_layer = self.forced_rules.get_forced_layer(features.semantic_class)\n",
        "            class_name = self.idx_to_info.get(features.semantic_class, {}).get('name', 'Unknown')\n",
        "            print(f\"    [FORCED] Class '{class_name}' -> Layer {forced_layer} (Background)\")\n",
        "            return forced_layer, 1.0, {'reason': 'forced_semantic_rule', 'class_name': class_name, 'features': features}\n",
        "\n",
        "        if not features.is_closed:\n",
        "            dominant_label = self._get_dominant_kmeans_label(region_mask)\n",
        "            return dominant_label, 0.95, {'reason': 'open_object', 'features': features}\n",
        "\n",
        "        strategies_results = {}\n",
        "        strategies_results['bottom'] = self._adaptive_bottom_sampling_strategy(region_mask, features)\n",
        "        strategies_results['horizontal'] = self._intelligent_horizontal_strategy(region_mask, features)\n",
        "        strategies_results['vertical'] = self._vertical_structure_strategy(region_mask, features)\n",
        "        strategies_results['spatial'] = self._spatial_context_strategy(region_mask, features)\n",
        "        strategies_results['depth'] = self._depth_consistency_strategy(region_mask, features)\n",
        "\n",
        "        return self._intelligent_fusion(strategies_results, features)\n",
        "\n",
        "    def _adaptive_bottom_sampling_strategy(self, region_mask, features):\n",
        "        bottom_ratio = self._get_intelligent_bottom_ratio(features)\n",
        "        weight_modifier = 1.0\n",
        "        if not features.touching_ground:\n",
        "            weight_modifier = 0.5\n",
        "        if features.effective_aspect_ratio < 0.5:\n",
        "            weight_modifier *= 0.7\n",
        "\n",
        "        y_coords, x_coords = np.where(region_mask)\n",
        "        num_bottom_pixels = max(int(features.num_pixels * bottom_ratio), min(10, features.num_pixels), min(features.num_pixels, 50))\n",
        "        y_sorted_indices = np.argsort(y_coords)[::-1]\n",
        "        bottom_indices = y_sorted_indices[:num_bottom_pixels]\n",
        "\n",
        "        bottom_labels = []\n",
        "        bottom_depths = []\n",
        "        for idx in bottom_indices:\n",
        "            y, x = y_coords[idx], x_coords[idx]\n",
        "            bottom_labels.append(self.fmb_map[y, x])\n",
        "            bottom_depths.append(self.depth_map[y, x])\n",
        "\n",
        "        layer_scores = self._calculate_layer_scores(bottom_labels, bottom_depths, features)\n",
        "        best_layer = max(layer_scores, key=layer_scores.get)\n",
        "        confidence = layer_scores[best_layer] / sum(layer_scores.values())\n",
        "\n",
        "        return {'layer': best_layer, 'confidence': confidence * weight_modifier, 'method': 'bottom_sampling',\n",
        "                'details': {'bottom_ratio': bottom_ratio, 'num_samples': num_bottom_pixels, 'layer_scores': layer_scores}}\n",
        "\n",
        "    def _intelligent_horizontal_strategy(self, region_mask, features):\n",
        "        if features.effective_aspect_ratio < 0.7 or features.elongation > 2.0:\n",
        "            return self._row_by_row_analysis(region_mask, features)\n",
        "        else:\n",
        "            return self._optimized_horizontal_analysis(region_mask, features)\n",
        "\n",
        "    def _row_by_row_analysis(self, region_mask, features):\n",
        "        y_coords, x_coords = np.where(region_mask)\n",
        "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
        "        row_analyses = []\n",
        "        window_size = max(3, int((y_max - y_min) * 0.1))\n",
        "\n",
        "        for y in range(y_min, y_max + 1):\n",
        "            row_mask = (y_coords == y)\n",
        "            if np.sum(row_mask) > 0:\n",
        "                window_start = max(y_min, y - window_size // 2)\n",
        "                window_end = min(y_max, y + window_size // 2)\n",
        "                window_mask = (y_coords >= window_start) & (y_coords <= window_end)\n",
        "                window_x = x_coords[window_mask]\n",
        "                window_y = y_coords[window_mask]\n",
        "                window_labels = self.fmb_map[window_y, window_x]\n",
        "                unique_labels, counts = np.unique(window_labels, return_counts=True)\n",
        "                dominant_label = unique_labels[np.argmax(counts)]\n",
        "                confidence = counts[np.argmax(counts)] / len(window_labels)\n",
        "                row_analyses.append({'y': y, 'dominant_layer': dominant_label, 'confidence': confidence, 'pixel_count': np.sum(row_mask)})\n",
        "\n",
        "        vertical_pattern = self._analyze_vertical_pattern_advanced(row_analyses)\n",
        "        final_layer, final_confidence = self._decide_from_row_analysis(row_analyses, vertical_pattern, features)\n",
        "\n",
        "        return {'layer': final_layer, 'confidence': final_confidence, 'method': 'row_by_row',\n",
        "                'details': {'num_rows': len(row_analyses), 'vertical_pattern': vertical_pattern}}\n",
        "\n",
        "    def _vertical_structure_strategy(self, region_mask, features):\n",
        "        y_coords, x_coords = np.where(region_mask)\n",
        "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
        "        height = y_max - y_min + 1\n",
        "        top_threshold = y_min + height * 0.33\n",
        "        bottom_threshold = y_max - height * 0.33\n",
        "\n",
        "        sections = {\n",
        "            'top': (y_coords <= top_threshold),\n",
        "            'middle': (y_coords > top_threshold) & (y_coords < bottom_threshold),\n",
        "            'bottom': (y_coords >= bottom_threshold)\n",
        "        }\n",
        "\n",
        "        section_analysis = {}\n",
        "        for section_name, section_mask in sections.items():\n",
        "            if np.sum(section_mask) > 0:\n",
        "                section_x = x_coords[section_mask]\n",
        "                section_y = y_coords[section_mask]\n",
        "                section_labels = self.fmb_map[section_y, section_x]\n",
        "                section_depths = self.depth_map[section_y, section_x]\n",
        "                unique_labels, counts = np.unique(section_labels, return_counts=True)\n",
        "                dominant_label = unique_labels[np.argmax(counts)]\n",
        "                section_analysis[section_name] = {\n",
        "                    'dominant_layer': dominant_label,\n",
        "                    'layer_confidence': counts[np.argmax(counts)] / np.sum(counts),\n",
        "                    'mean_depth': np.mean(section_depths),\n",
        "                    'depth_std': np.std(section_depths)\n",
        "                }\n",
        "\n",
        "        if 'bottom' in section_analysis and 'top' in section_analysis:\n",
        "            if section_analysis['bottom']['dominant_layer'] == section_analysis['top']['dominant_layer']:\n",
        "                final_layer = section_analysis['bottom']['dominant_layer']\n",
        "                confidence = 0.8\n",
        "            else:\n",
        "                final_layer = section_analysis['bottom']['dominant_layer']\n",
        "                confidence = 0.6\n",
        "        else:\n",
        "            available_section = list(section_analysis.values())[0]\n",
        "            final_layer = available_section['dominant_layer']\n",
        "            confidence = available_section['layer_confidence'] * 0.7\n",
        "\n",
        "        return {'layer': final_layer, 'confidence': confidence, 'method': 'vertical_structure', 'details': section_analysis}\n",
        "\n",
        "    def _spatial_context_strategy(self, region_mask, features):\n",
        "        if features.touching_sky and features.semantic_class in self.sky_classes:\n",
        "            return {'layer': 2, 'confidence': 0.9, 'method': 'spatial_context', 'details': {'reason': 'touching_sky'}}\n",
        "\n",
        "        if features.touching_ground and features.relative_y_position > 0.7:\n",
        "            return {'layer': 0, 'confidence': 0.7, 'method': 'spatial_context', 'details': {'reason': 'touching_ground_bottom'}}\n",
        "\n",
        "        if features.relative_y_position < 0.3:\n",
        "            suggested_layer = 2\n",
        "            confidence = 0.4\n",
        "        elif features.relative_y_position > 0.7:\n",
        "            suggested_layer = 0\n",
        "            confidence = 0.4\n",
        "        else:\n",
        "            suggested_layer = 1\n",
        "            confidence = 0.3\n",
        "\n",
        "        neighbor_layers = self._analyze_neighbor_layers(region_mask, features)\n",
        "        if neighbor_layers:\n",
        "            most_common_neighbor = max(neighbor_layers, key=neighbor_layers.count)\n",
        "            if neighbor_layers.count(most_common_neighbor) > len(neighbor_layers) * 0.6:\n",
        "                suggested_layer = most_common_neighbor\n",
        "                confidence += 0.2\n",
        "\n",
        "        return {'layer': suggested_layer, 'confidence': min(confidence, 0.6), 'method': 'spatial_context',\n",
        "                'details': {'relative_position': features.relative_y_position, 'neighbor_influence': len(neighbor_layers) > 0}}\n",
        "\n",
        "    def _depth_consistency_strategy(self, region_mask, features):\n",
        "        layer_depth_profiles = self._get_layer_depth_profiles()\n",
        "        match_scores = {}\n",
        "        for layer, (depth_mean, depth_std) in layer_depth_profiles.items():\n",
        "            z_score = abs(features.depth_mean - depth_mean) / (depth_std + 1e-6)\n",
        "            match_scores[layer] = np.exp(-0.5 * z_score ** 2)\n",
        "\n",
        "        if features.depth_std > 20:\n",
        "            for layer in match_scores:\n",
        "                match_scores[layer] *= 0.7\n",
        "\n",
        "        best_layer = max(match_scores, key=match_scores.get)\n",
        "        confidence = match_scores[best_layer]\n",
        "        if features.depth_std < 10:\n",
        "            confidence = min(confidence * 1.2, 0.9)\n",
        "\n",
        "        return {'layer': best_layer, 'confidence': confidence, 'method': 'depth_consistency',\n",
        "                'details': {'match_scores': match_scores, 'depth_std': features.depth_std}}\n",
        "\n",
        "    def _intelligent_fusion(self, strategies_results, features):\n",
        "        layer_votes = {0: 0, 1: 0, 2: 0}\n",
        "        strategy_details = {}\n",
        "        adjusted_weights = self._adjust_strategy_weights(features)\n",
        "\n",
        "        for strategy_name, result in strategies_results.items():\n",
        "            layer = result['layer']\n",
        "            confidence = result['confidence']\n",
        "            weight = adjusted_weights.get(strategy_name, 0.2)\n",
        "            layer_votes[layer] += confidence * weight\n",
        "            strategy_details[strategy_name] = {'layer': layer, 'confidence': confidence, 'weight': weight, 'weighted_vote': confidence * weight}\n",
        "\n",
        "        total_votes = sum(layer_votes.values())\n",
        "        if total_votes > 0:\n",
        "            for layer in layer_votes:\n",
        "                layer_votes[layer] /= total_votes\n",
        "\n",
        "        final_layer = max(layer_votes, key=layer_votes.get)\n",
        "        base_confidence = layer_votes[final_layer]\n",
        "\n",
        "        agreeing_strategies = sum(1 for r in strategies_results.values() if r['layer'] == final_layer)\n",
        "        if agreeing_strategies >= 3:\n",
        "            consistency_bonus = 0.1 * (agreeing_strategies - 2)\n",
        "            base_confidence = min(base_confidence + consistency_bonus, 0.95)\n",
        "\n",
        "        vote_entropy = -sum(v * np.log(v + 1e-10) for v in layer_votes.values() if v > 0)\n",
        "        max_entropy = np.log(3)\n",
        "        if vote_entropy > max_entropy * 0.8:\n",
        "            base_confidence *= 0.8\n",
        "\n",
        "        final_confidence = self._apply_special_rules(final_layer, base_confidence, features, strategy_details)\n",
        "\n",
        "        return final_layer, final_confidence, {\n",
        "            'layer_votes': layer_votes, 'strategy_details': strategy_details,\n",
        "            'adjusted_weights': adjusted_weights, 'agreeing_strategies': agreeing_strategies,\n",
        "            'vote_entropy': vote_entropy, 'features': features\n",
        "        }\n",
        "\n",
        "    def _adjust_strategy_weights(self, features):\n",
        "        weights = self.strategy_weights.copy()\n",
        "        if features.effective_aspect_ratio < 0.5:\n",
        "            weights['horizontal_analysis'] *= 1.5\n",
        "            weights['bottom_sampling'] *= 0.7\n",
        "        elif features.effective_aspect_ratio > 2.0:\n",
        "            weights['vertical_structure'] *= 1.3\n",
        "\n",
        "        if features.num_pixels < 100:\n",
        "            weights['vertical_structure'] *= 0.5\n",
        "            weights['spatial_context'] *= 1.2\n",
        "        elif features.num_pixels > 5000:\n",
        "            for key in weights:\n",
        "                weights[key] *= 1.1\n",
        "\n",
        "        if features.touching_ground:\n",
        "            weights['bottom_sampling'] *= 1.3\n",
        "        if features.touching_sky:\n",
        "            weights['spatial_context'] *= 1.4\n",
        "\n",
        "        if features.depth_std < 10:\n",
        "            weights['depth_consistency'] *= 1.5\n",
        "        elif features.depth_std > 50:\n",
        "            weights['depth_consistency'] *= 0.5\n",
        "\n",
        "        total_weight = sum(weights.values())\n",
        "        for key in weights:\n",
        "            weights[key] /= total_weight\n",
        "        return weights\n",
        "\n",
        "    def _apply_special_rules(self, layer, confidence, features, strategy_details):\n",
        "        if features.is_countable and features.depth_range > 50:\n",
        "            if confidence < 0.6:\n",
        "                confidence *= 0.8\n",
        "\n",
        "        if features.relative_y_position < 0.1 and layer != 2:\n",
        "            confidence *= 0.8\n",
        "        elif features.relative_y_position > 0.9 and layer != 0:\n",
        "            confidence *= 0.8\n",
        "\n",
        "        if 'spatial_context' in strategy_details:\n",
        "            spatial_conf = strategy_details['spatial_context']['confidence']\n",
        "            if spatial_conf > 0.7:\n",
        "                confidence = confidence * 0.8 + spatial_conf * 0.2\n",
        "\n",
        "        return min(confidence, 0.95)\n",
        "\n",
        "    # ========== Helper Methods ==========\n",
        "\n",
        "    def _calculate_effective_aspect_ratio(self, region_mask):\n",
        "        y_coords, x_coords = np.where(region_mask)\n",
        "        if len(y_coords) == 0:\n",
        "            return 1.0\n",
        "        unique_rows = len(np.unique(y_coords))\n",
        "        unique_cols = len(np.unique(x_coords))\n",
        "        return unique_rows / unique_cols if unique_cols > 0 else 1.0\n",
        "\n",
        "    def _get_intelligent_bottom_ratio(self, features):\n",
        "        if features.num_pixels < 100:\n",
        "            base_ratio = 0.25\n",
        "        elif features.num_pixels < 500:\n",
        "            base_ratio = 0.15\n",
        "        elif features.num_pixels < 2000:\n",
        "            base_ratio = 0.10\n",
        "        else:\n",
        "            base_ratio = 0.05\n",
        "\n",
        "        if features.effective_aspect_ratio < 0.5:\n",
        "            base_ratio *= 1.5\n",
        "        elif features.elongation > 3.0:\n",
        "            base_ratio *= 0.7\n",
        "        if not features.touching_ground:\n",
        "            base_ratio *= 0.5\n",
        "        return min(base_ratio, 0.5)\n",
        "\n",
        "    def _calculate_vertical_gradient(self, region_mask, depths, y_coords):\n",
        "        if len(y_coords) < 10:\n",
        "            return 0.0\n",
        "        y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
        "        if y_max <= y_min:\n",
        "            return 0.0\n",
        "        top_mask = y_coords <= y_min + (y_max - y_min) * 0.2\n",
        "        bottom_mask = y_coords >= y_max - (y_max - y_min) * 0.2\n",
        "        if np.sum(top_mask) > 0 and np.sum(bottom_mask) > 0:\n",
        "            top_depth = np.mean(depths[top_mask])\n",
        "            bottom_depth = np.mean(depths[bottom_mask])\n",
        "            return abs(bottom_depth - top_depth) / (y_max - y_min)\n",
        "        return 0.0\n",
        "\n",
        "    def _calculate_horizontal_gradient(self, region_mask, depths, x_coords):\n",
        "        if len(x_coords) < 10:\n",
        "            return 0.0\n",
        "        x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
        "        if x_max <= x_min:\n",
        "            return 0.0\n",
        "        left_mask = x_coords <= x_min + (x_max - x_min) * 0.2\n",
        "        right_mask = x_coords >= x_max - (x_max - x_min) * 0.2\n",
        "        if np.sum(left_mask) > 0 and np.sum(right_mask) > 0:\n",
        "            left_depth = np.mean(depths[left_mask])\n",
        "            right_depth = np.mean(depths[right_mask])\n",
        "            return abs(right_depth - left_depth) / (x_max - x_min)\n",
        "        return 0.0\n",
        "\n",
        "    def _get_neighbor_classes(self, region_mask):\n",
        "        dilated = ndimage.binary_dilation(region_mask, iterations=3)\n",
        "        neighbor_mask = dilated & (~region_mask)\n",
        "        if np.sum(neighbor_mask) == 0:\n",
        "            return []\n",
        "        neighbor_values = self.semantic_map[neighbor_mask]\n",
        "        unique_classes = np.unique(neighbor_values)\n",
        "        return unique_classes.tolist()\n",
        "\n",
        "    def _calculate_edge_density(self, region_mask):\n",
        "        if np.sum(region_mask) < 10:\n",
        "            return 0.0\n",
        "        region_depth = self.depth_map.copy()\n",
        "        region_depth[~region_mask] = 0\n",
        "        edges_x = ndimage.sobel(region_depth, axis=1)\n",
        "        edges_y = ndimage.sobel(region_depth, axis=0)\n",
        "        edge_magnitude = np.sqrt(edges_x**2 + edges_y**2)\n",
        "        return np.mean(edge_magnitude[region_mask])\n",
        "\n",
        "    def _calculate_internal_structure(self, region_mask):\n",
        "        if np.sum(region_mask) < 20:\n",
        "            return 0.0\n",
        "        region_depth = self.depth_map[region_mask]\n",
        "        return np.std(region_depth) / (np.mean(region_depth) + 1e-6)\n",
        "\n",
        "    def _get_dominant_kmeans_label(self, region_mask):\n",
        "        labels = self.fmb_map[region_mask]\n",
        "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "        return unique_labels[np.argmax(counts)]\n",
        "\n",
        "    def _calculate_layer_scores(self, labels, depths, features):\n",
        "        layer_scores = {0: 0.01, 1: 0.01, 2: 0.01}\n",
        "        for layer in [0, 1, 2]:\n",
        "            layer_mask = np.array(labels) == layer\n",
        "            if np.sum(layer_mask) > 0:\n",
        "                base_score = np.sum(layer_mask) / len(labels)\n",
        "                layer_depths = np.array(depths)[layer_mask]\n",
        "                depth_consistency = 1.0 / (1.0 + np.std(layer_depths) / 10)\n",
        "                semantic_bonus = self._get_semantic_layer_compatibility(features.semantic_class, layer)\n",
        "                layer_scores[layer] = base_score * depth_consistency * semantic_bonus\n",
        "\n",
        "        total_score = sum(layer_scores.values())\n",
        "        if total_score > 0:\n",
        "            for layer in layer_scores:\n",
        "                layer_scores[layer] /= total_score\n",
        "        return layer_scores\n",
        "\n",
        "    def _get_semantic_layer_compatibility(self, semantic_class, layer):\n",
        "        \"\"\"Get compatibility between semantic class and layer - UPDATED keywords\"\"\"\n",
        "        if semantic_class in self.idx_to_info:\n",
        "            name = self.idx_to_info[semantic_class]['name'].lower()\n",
        "\n",
        "            # Foreground tendency\n",
        "            if any(word in name for word in [\n",
        "                'person', 'individual', 'people', 'car', 'auto', 'automobile', \n",
        "                'chair', 'trash', 'ashcan', 'garbage', 'bin', 'bicycle', 'bike', \n",
        "                'bus', 'truck', 'van', 'motorbike', 'animal', 'dog', 'cat',\n",
        "                'table', 'desk', 'sofa', 'couch', 'bed', 'armchair', 'seat',\n",
        "                'bench', 'stool', 'ottoman'\n",
        "            ]):\n",
        "                return [1.2, 1.0, 0.8][layer]\n",
        "\n",
        "            # Background tendency\n",
        "            elif any(word in name for word in [\n",
        "                'sky', 'mountain', 'mount', 'hill', 'sea', 'cloud', 'horizon'\n",
        "            ]):\n",
        "                return [0.6, 0.8, 1.3][layer]\n",
        "\n",
        "            # Middleground tendency\n",
        "            elif any(word in name for word in [\n",
        "                'tree', 'building', 'edifice', 'wall', 'house', 'fence', \n",
        "                'tower', 'bridge', 'skyscraper', 'palm'\n",
        "            ]):\n",
        "                return [0.9, 1.1, 0.9][layer]\n",
        "\n",
        "        return 1.0\n",
        "\n",
        "    def _analyze_vertical_pattern_advanced(self, row_analyses):\n",
        "        if len(row_analyses) < 3:\n",
        "            return 'uniform'\n",
        "        layers = [r['dominant_layer'] for r in row_analyses]\n",
        "        changes = sum(1 for i in range(1, len(layers)) if layers[i] != layers[i-1])\n",
        "        max_streak = 1\n",
        "        current_streak = 1\n",
        "        for i in range(1, len(layers)):\n",
        "            if layers[i] == layers[i-1]:\n",
        "                current_streak += 1\n",
        "                max_streak = max(max_streak, current_streak)\n",
        "            else:\n",
        "                current_streak = 1\n",
        "\n",
        "        change_ratio = changes / len(layers)\n",
        "        streak_ratio = max_streak / len(layers)\n",
        "\n",
        "        if change_ratio < 0.1:\n",
        "            return 'uniform'\n",
        "        elif change_ratio < 0.3 and streak_ratio > 0.5:\n",
        "            return 'gradient'\n",
        "        elif changes == 1:\n",
        "            return 'split'\n",
        "        else:\n",
        "            return 'chaotic'\n",
        "\n",
        "    def _decide_from_row_analysis(self, row_analyses, vertical_pattern, features):\n",
        "        layer_votes = {0: 0, 1: 0, 2: 0}\n",
        "        for analysis in row_analyses:\n",
        "            layer = analysis['dominant_layer']\n",
        "            confidence = analysis['confidence']\n",
        "            pixels = analysis['pixel_count']\n",
        "            weight = confidence * pixels\n",
        "            layer_votes[layer] += weight\n",
        "\n",
        "        total_votes = sum(layer_votes.values())\n",
        "        if total_votes > 0:\n",
        "            best_layer = max(layer_votes, key=layer_votes.get)\n",
        "            base_confidence = layer_votes[best_layer] / total_votes\n",
        "\n",
        "            if vertical_pattern == 'uniform':\n",
        "                final_confidence = min(base_confidence + 0.1, 0.95)\n",
        "            elif vertical_pattern == 'chaotic':\n",
        "                final_confidence = base_confidence * 0.8\n",
        "            else:\n",
        "                final_confidence = base_confidence\n",
        "            return best_layer, final_confidence\n",
        "        return 1, 0.5\n",
        "\n",
        "    def _optimized_horizontal_analysis(self, region_mask, features):\n",
        "        labels = self.fmb_map[region_mask]\n",
        "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "        dominant_label = unique_labels[np.argmax(counts)]\n",
        "        confidence = counts[np.argmax(counts)] / len(labels)\n",
        "\n",
        "        if len(unique_labels) > 1:\n",
        "            distribution_entropy = -sum((c/len(labels)) * np.log(c/len(labels)) for c in counts)\n",
        "            max_entropy = np.log(len(unique_labels))\n",
        "            if distribution_entropy > max_entropy * 0.7:\n",
        "                confidence *= 0.8\n",
        "\n",
        "        return {'layer': dominant_label, 'confidence': confidence, 'method': 'horizontal_simple',\n",
        "                'details': {'unique_labels': len(unique_labels), 'dominant_ratio': confidence}}\n",
        "\n",
        "    def _get_layer_depth_profiles(self):\n",
        "        profiles = {}\n",
        "        for layer in [0, 1, 2]:\n",
        "            layer_mask = self.fmb_map == layer\n",
        "            if np.sum(layer_mask) > 0:\n",
        "                layer_depths = self.depth_map[layer_mask]\n",
        "                profiles[layer] = (np.mean(layer_depths), np.std(layer_depths))\n",
        "            else:\n",
        "                if layer == 0:\n",
        "                    profiles[layer] = (200, 30)\n",
        "                elif layer == 1:\n",
        "                    profiles[layer] = (128, 40)\n",
        "                else:\n",
        "                    profiles[layer] = (50, 30)\n",
        "        return profiles\n",
        "\n",
        "    def _analyze_neighbor_layers(self, region_mask, features):\n",
        "        neighbor_layers = []\n",
        "        for neighbor_class in features.neighbor_classes:\n",
        "            neighbor_mask = self.semantic_map == neighbor_class\n",
        "            if np.sum(neighbor_mask) > 0:\n",
        "                neighbor_labels = self.fmb_map[neighbor_mask]\n",
        "                unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n",
        "                dominant_label = unique_labels[np.argmax(counts)]\n",
        "                neighbor_layers.append(dominant_label)\n",
        "        return neighbor_layers\n",
        "\n",
        "# ==================== Basic Functions ====================\n",
        "\n",
        "def hex2rgb(hex_color):\n",
        "    \"\"\"Convert hexadecimal color to RGB tuple\"\"\"\n",
        "    hex_color = hex_color.lstrip('#')\n",
        "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
        "\n",
        "def read_config_from_json(json_path):\n",
        "    \"\"\"Read configuration from JSON file\"\"\"\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    color_to_idx = {}\n",
        "    idx_to_info = {}\n",
        "    openness = []\n",
        "    countability = []\n",
        "    idx = 1\n",
        "\n",
        "    for entry in data:\n",
        "        rgb = hex2rgb(entry['color'])\n",
        "        color_to_idx[rgb] = idx\n",
        "        open_value = int(entry['openness'])\n",
        "        countable_value = int(entry['countable'])\n",
        "\n",
        "        idx_to_info[idx] = {\n",
        "            'name': entry['name'],\n",
        "            'openness': open_value,\n",
        "            'countable': countable_value,\n",
        "            'color': entry['color'].upper(),\n",
        "            'rgb': rgb\n",
        "        }\n",
        "        openness.append(open_value)\n",
        "        countability.append(countable_value)\n",
        "        idx += 1\n",
        "\n",
        "    return color_to_idx, idx_to_info, openness, countability\n",
        "\n",
        "def semantic_rgb_to_idx_map(semantic_img, color_to_idx):\n",
        "    \"\"\"Convert RGB semantic image to index map\"\"\"\n",
        "    H, W, _ = semantic_img.shape\n",
        "    semantic_map = np.zeros((H, W), dtype=np.uint8)\n",
        "    unique_colors = np.unique(semantic_img.reshape(-1, 3), axis=0)\n",
        "    print(f\"\\nDetected image colors: {unique_colors.shape[0]} unique colors\")\n",
        "    color_set = set(color_to_idx.keys())\n",
        "\n",
        "    for color in unique_colors:\n",
        "        rgb = tuple(color.tolist())\n",
        "        if rgb in color_set:\n",
        "            semantic_map[np.all(semantic_img == rgb, axis=2)] = color_to_idx[rgb]\n",
        "\n",
        "    return semantic_map\n",
        "\n",
        "def process_fmb_segmentation_with_intelligent_system(depth_map, semantic_map, openness,\n",
        "                                                   countability, idx_to_info,\n",
        "                                                   enable_hole_filling=True):\n",
        "    \"\"\"Perform FMB segmentation using intelligent system\"\"\"\n",
        "    H, W = depth_map.shape\n",
        "    print(f\"\\nProcessing image size: {W}x{H}\")\n",
        "    valid_mask = depth_map > 0\n",
        "    depth_valid = depth_map[valid_mask]\n",
        "\n",
        "    if len(depth_valid) == 0:\n",
        "        print(\"Warning: No valid depth values!\")\n",
        "        empty_map = np.full((H, W), 2, dtype=np.uint8)\n",
        "        return empty_map, empty_map, [], None, None\n",
        "\n",
        "    depth_sorted = np.sort(depth_valid)[::-1]\n",
        "    idx1 = int(len(depth_sorted) * 0.51)\n",
        "    idx2 = int(len(depth_sorted) * 0.77)\n",
        "\n",
        "    thresh1 = depth_sorted[idx1] if idx1 < len(depth_sorted) else depth_sorted[-1]\n",
        "    thresh2 = depth_sorted[idx2] if idx2 < len(depth_sorted) else depth_sorted[-1]\n",
        "\n",
        "    print(f\"Theoretical depth thresholds based on 51%-26%-23%:\")\n",
        "    print(f\"  Foreground>{thresh1:.1f} (51%), Middleground {thresh2:.1f}-{thresh1:.1f} (26%), Background<{thresh2:.1f} (23%)\")\n",
        "\n",
        "    # Feature engineering\n",
        "    n_features = 2\n",
        "    features = np.zeros((np.sum(valid_mask), n_features))\n",
        "\n",
        "    initial_labels = np.zeros_like(depth_valid, dtype=float)\n",
        "    initial_labels[depth_valid > thresh1] = 0.0\n",
        "    initial_labels[(depth_valid <= thresh1) & (depth_valid > thresh2)] = 1.0\n",
        "    initial_labels[depth_valid <= thresh2] = 2.0\n",
        "    features[:, 0] = initial_labels\n",
        "\n",
        "    boundary_sensitivity = np.zeros_like(depth_valid, dtype=float)\n",
        "    boundary_range = (np.max(depth_valid) - np.min(depth_valid)) * 0.08\n",
        "\n",
        "    for i, d in enumerate(depth_valid):\n",
        "        dist_to_thresh1 = abs(d - thresh1)\n",
        "        dist_to_thresh2 = abs(d - thresh2)\n",
        "        min_boundary_dist = min(dist_to_thresh1, dist_to_thresh2)\n",
        "        if min_boundary_dist <= boundary_range:\n",
        "            boundary_sensitivity[i] = np.exp(-min_boundary_dist**2 / (2 * (boundary_range/3)**2))\n",
        "        else:\n",
        "            boundary_sensitivity[i] = 0.0\n",
        "\n",
        "    features[:, 1] = boundary_sensitivity\n",
        "    weights = np.array([0.95, 0.05])\n",
        "    weighted_features = features * weights\n",
        "\n",
        "    print(f\"\\nFeature engineering statistics:\")\n",
        "    print(f\"  - Pixels near boundaries (sensitivity > 0.1): {np.sum(boundary_sensitivity > 0.1)} \"\n",
        "          f\"({np.sum(boundary_sensitivity > 0.1) / len(depth_valid) * 100:.1f}%)\")\n",
        "    print(f\"  - Average boundary sensitivity: {np.mean(boundary_sensitivity):.3f}\")\n",
        "\n",
        "    # K-means\n",
        "    centers = np.zeros((3, n_features))\n",
        "    for i in range(3):\n",
        "        centers[i][0] = i * weights[0]\n",
        "        centers[i][1] = 0.0\n",
        "\n",
        "    print(\"\\nPerforming simplified K-means clustering...\")\n",
        "\n",
        "    try:\n",
        "        kmeans = KMeans(n_clusters=3, init=centers, n_init=1, max_iter=50, random_state=42, tol=1e-4)\n",
        "        cluster_labels = kmeans.fit_predict(weighted_features)\n",
        "        print(\"\\nValidating K-means adherence to theory...\")\n",
        "\n",
        "        for i in range(3):\n",
        "            cluster_mask = cluster_labels == i\n",
        "            if np.sum(cluster_mask) > 0:\n",
        "                theory_labels_in_cluster = initial_labels[cluster_mask]\n",
        "                unique_theory, counts = np.unique(theory_labels_in_cluster, return_counts=True)\n",
        "                main_theory_count = counts[np.argmax(counts)]\n",
        "                total_in_cluster = np.sum(cluster_mask)\n",
        "                purity = main_theory_count / total_in_cluster\n",
        "                print(f\"  Cluster {i}: {purity*100:.1f}% consistent with theory\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"K-means failed: {e}, using theory-based assignment\")\n",
        "        cluster_labels = initial_labels.astype(int)\n",
        "\n",
        "    # Map cluster labels\n",
        "    cluster_depths = []\n",
        "    for i in range(3):\n",
        "        mask = cluster_labels == i\n",
        "        if np.sum(mask) > 0:\n",
        "            cluster_depths.append(np.mean(depth_valid[mask]))\n",
        "        else:\n",
        "            cluster_depths.append(0)\n",
        "\n",
        "    depth_order = np.argsort(cluster_depths)[::-1]\n",
        "    label_mapping = {depth_order[i]: i for i in range(3)}\n",
        "\n",
        "    fmb_map = np.full((H, W), 2, dtype=np.uint8)\n",
        "    valid_coords = np.where(valid_mask)\n",
        "    for idx, (y, x) in enumerate(zip(valid_coords[0], valid_coords[1])):\n",
        "        original_label = cluster_labels[idx]\n",
        "        mapped_label = label_mapping[original_label]\n",
        "        fmb_map[y, x] = mapped_label\n",
        "\n",
        "    kmeans_original = fmb_map.copy()\n",
        "\n",
        "    # Initialize Forced Semantic Rules\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Initializing Forced Semantic Rules...\")\n",
        "    print(\"=\" * 50)\n",
        "    forced_rules = ForcedSemanticRules(idx_to_info)\n",
        "\n",
        "    # Apply Forced Rules FIRST\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Applying Forced Semantic Rules...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    forced_adjustments = 0\n",
        "    for sem_class in np.unique(semantic_map):\n",
        "        if sem_class == 0:\n",
        "            continue\n",
        "        \n",
        "        forced_layer = forced_rules.get_forced_layer(sem_class)\n",
        "        if forced_layer is not None:\n",
        "            class_mask = semantic_map == sem_class\n",
        "            pixel_count = np.sum(class_mask)\n",
        "            if pixel_count > 0:\n",
        "                class_name = idx_to_info.get(sem_class, {}).get('name', f'Class_{sem_class}')\n",
        "                current_layers = fmb_map[class_mask]\n",
        "                changed_pixels = np.sum(current_layers != forced_layer)\n",
        "                fmb_map[class_mask] = forced_layer\n",
        "                print(f\"  {class_name}: {pixel_count} pixels -> Layer {forced_layer} (Background)\")\n",
        "                print(f\"    Changed {changed_pixels} pixels ({changed_pixels/pixel_count*100:.1f}%)\")\n",
        "                forced_adjustments += 1\n",
        "    \n",
        "    print(f\"\\nForced rule adjustments: {forced_adjustments} classes processed\")\n",
        "\n",
        "    # Intelligent Connectivity Processing\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Processing closed objects with intelligent system...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    decision_system = IntelligentLayerDecisionSystem(\n",
        "        depth_map, semantic_map, fmb_map, openness, countability, idx_to_info,\n",
        "        forced_rules=forced_rules\n",
        "    )\n",
        "\n",
        "    adjustments = []\n",
        "    adjustment_count = 0\n",
        "\n",
        "    unique_classes = np.unique(semantic_map)\n",
        "    for sem_class in unique_classes:\n",
        "        if sem_class == 0:\n",
        "            continue\n",
        "\n",
        "        if sem_class <= len(openness) and openness[sem_class - 1] == 1:\n",
        "            class_name = idx_to_info[sem_class]['name']\n",
        "            \n",
        "            if forced_rules.is_forced(sem_class):\n",
        "                print(f\"\\nSkipping {class_name} (already processed by forced rules)\")\n",
        "                continue\n",
        "                \n",
        "            print(f\"\\nProcessing closed class: {class_name}\")\n",
        "\n",
        "            class_mask = (semantic_map == sem_class).astype(np.uint8)\n",
        "            labeled_array, num_features = ndimage.label(class_mask)\n",
        "            print(f\"  Found {num_features} connected components\")\n",
        "\n",
        "            for region_id in range(1, num_features + 1):\n",
        "                region_mask = labeled_array == region_id\n",
        "                pixel_count = np.sum(region_mask)\n",
        "\n",
        "                if pixel_count < 20:\n",
        "                    continue\n",
        "\n",
        "                result = decision_system.intelligent_layer_decision(region_mask)\n",
        "                if result[0] is not None:\n",
        "                    layer, confidence, details = result\n",
        "\n",
        "                    current_labels = fmb_map[region_mask]\n",
        "                    if not np.all(current_labels == layer):\n",
        "                        fmb_map[region_mask] = layer\n",
        "                        adjustment_count += 1\n",
        "\n",
        "                        adjustments.append({\n",
        "                            'class': sem_class, 'class_name': idx_to_info[sem_class]['name'],\n",
        "                            'region': region_id, 'layer': layer, 'confidence': confidence, 'details': details\n",
        "                        })\n",
        "\n",
        "                        print(f\"\\n  Adjusted object: {idx_to_info[sem_class]['name']} (region {region_id})\")\n",
        "                        print(f\"    Decided layer: {['Foreground', 'Middleground', 'Background'][layer]}\")\n",
        "                        print(f\"    Confidence: {confidence:.2f}\")\n",
        "\n",
        "    if adjustment_count > 0:\n",
        "        print(f\"\\nProcessing complete: Unified {adjustment_count} closed objects to single layers\")\n",
        "\n",
        "    # Hole Filling\n",
        "    fmb_before_filling = None\n",
        "    fill_info = None\n",
        "\n",
        "    if enable_hole_filling:\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"Executing intelligent hole filling post-processing...\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        fmb_before_filling = fmb_map.copy()\n",
        "        hole_filler = IntelligentHoleFilling(depth_map, fmb_map)\n",
        "        fmb_map, fill_info = hole_filler.process()\n",
        "        adjustments.append({'type': 'hole_filling', 'info': fill_info})\n",
        "\n",
        "    # Statistics\n",
        "    print(\"\\nFinal deviation from theoretical distribution:\")\n",
        "    total_valid = np.sum(valid_mask)\n",
        "    for i in range(3):\n",
        "        actual_count = np.sum(fmb_map == i)\n",
        "        actual_pct = (actual_count / total_valid) * 100 if total_valid > 0 else 0\n",
        "        theory_pct = [51.0, 26.0, 23.0][i]\n",
        "        deviation = actual_pct - theory_pct\n",
        "        print(f\"  Layer {i}: {actual_pct:.1f}% (theory: {theory_pct}%, deviation: {deviation:+.1f}%)\")\n",
        "\n",
        "    return fmb_map, kmeans_original, adjustments, fmb_before_filling, fill_info\n",
        "\n",
        "# ==================== Visualization Functions ====================\n",
        "\n",
        "def create_colored_fmb_map(fmb_map):\n",
        "    \"\"\"Create colored visualization of FMB map\"\"\"\n",
        "    fmb_colors = {0: [220, 20, 60], 1: [46, 125, 50], 2: [30, 144, 255]}\n",
        "    H, W = fmb_map.shape\n",
        "    colored_fmb = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for value, color in fmb_colors.items():\n",
        "        mask = fmb_map == value\n",
        "        colored_fmb[mask] = color\n",
        "    return colored_fmb\n",
        "\n",
        "def visualize_semantic_with_original_colors(semantic_map, idx_to_info):\n",
        "    H, W = semantic_map.shape\n",
        "    colored_semantic = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for idx, info in idx_to_info.items():\n",
        "        mask = semantic_map == idx\n",
        "        colored_semantic[mask] = info['rgb']\n",
        "    return colored_semantic\n",
        "\n",
        "def visualize_closed_objects(semantic_map, openness):\n",
        "    H, W = semantic_map.shape\n",
        "    colored_objects = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    object_id = 0\n",
        "    np.random.seed(42)\n",
        "    unique_classes = np.unique(semantic_map)\n",
        "    print(f\"\\nChecking closed objects...\")\n",
        "    closed_found = 0\n",
        "\n",
        "    for sem_class in unique_classes:\n",
        "        if sem_class > 0 and sem_class <= len(openness):\n",
        "            is_closed = openness[sem_class - 1]\n",
        "            if is_closed == 1:\n",
        "                closed_found += 1\n",
        "                class_mask = (semantic_map == sem_class).astype(np.uint8)\n",
        "                labeled_array, num_features = ndimage.label(class_mask)\n",
        "                for region_id in range(1, num_features + 1):\n",
        "                    region_mask = labeled_array == region_id\n",
        "                    color = np.random.randint(50, 256, 3)\n",
        "                    while np.mean(color) < 80 or np.mean(color) > 200:\n",
        "                        color = np.random.randint(50, 256, 3)\n",
        "                    colored_objects[region_mask] = color\n",
        "                    object_id += 1\n",
        "\n",
        "    return colored_objects, object_id\n",
        "\n",
        "def visualize_adjustment_process(kmeans_original, fmb_map, semantic_map, openness):\n",
        "    H, W = fmb_map.shape\n",
        "    adjustment_vis = {}\n",
        "    adjustment_mask = kmeans_original != fmb_map\n",
        "    adjustment_vis['mask'] = adjustment_mask\n",
        "    adjusted_objects_map = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    object_adjustment_info = []\n",
        "\n",
        "    if semantic_map is not None and openness is not None:\n",
        "        unique_classes = np.unique(semantic_map)\n",
        "        for sem_class in unique_classes:\n",
        "            if sem_class > 0 and sem_class <= len(openness):\n",
        "                if openness[sem_class - 1] == 1:\n",
        "                    class_mask = (semantic_map == sem_class).astype(np.uint8)\n",
        "                    labeled_array, num_features = ndimage.label(class_mask)\n",
        "                    for region_id in range(1, num_features + 1):\n",
        "                        region_mask = labeled_array == region_id\n",
        "                        if np.any(adjustment_mask[region_mask]):\n",
        "                            original_labels = kmeans_original[region_mask]\n",
        "                            final_labels = fmb_map[region_mask]\n",
        "                            orig_label = np.bincount(original_labels).argmax()\n",
        "                            final_label = final_labels[0]\n",
        "                            if orig_label != final_label:\n",
        "                                if orig_label < final_label:\n",
        "                                    color = [255, 100, 100]\n",
        "                                else:\n",
        "                                    color = [100, 255, 100]\n",
        "                                adjusted_objects_map[region_mask] = color\n",
        "                                object_adjustment_info.append({\n",
        "                                    'class': sem_class, 'object_id': region_id,\n",
        "                                    'from_layer': orig_label, 'to_layer': final_label,\n",
        "                                    'pixel_count': np.sum(region_mask)\n",
        "                                })\n",
        "\n",
        "    adjustment_vis['adjusted_objects_map'] = adjusted_objects_map\n",
        "    adjustment_vis['object_info'] = object_adjustment_info\n",
        "    return adjustment_vis\n",
        "\n",
        "def create_semantic_table(idx_to_info, semantic_map):\n",
        "    present_classes = np.unique(semantic_map[semantic_map > 0])\n",
        "    print(f\"\\nSemantic categories found in image: {present_classes}\")\n",
        "    table_data = []\n",
        "\n",
        "    for class_id in present_classes:\n",
        "        if class_id in idx_to_info:\n",
        "            info = idx_to_info[class_id]\n",
        "            openness_str = \"Closed\" if info['openness'] == 1 else \"Open\"\n",
        "            countable_str = \"Countable\" if info['countable'] == 1 else \"Uncountable\"\n",
        "            pixels = np.sum(semantic_map == class_id)\n",
        "            percentage = (pixels / semantic_map.size) * 100\n",
        "            table_data.append([class_id, info['name'], openness_str, countable_str, f\"{pixels:,}\", f\"{percentage:.1f}%\"])\n",
        "        else:\n",
        "            pixels = np.sum(semantic_map == class_id)\n",
        "            percentage = (pixels / semantic_map.size) * 100\n",
        "            table_data.append([class_id, f\"Unknown_Class_{class_id}\", \"Unknown\", \"Unknown\", f\"{pixels:,}\", f\"{percentage:.1f}%\"])\n",
        "\n",
        "    print(\"\\nSemantic Categories in Image:\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'ID':>4} | {'Category Name':<40} | {'Openness':<8} | {'Countable':<10} | {'Pixels':>10} | {'%':>6}\")\n",
        "    print(\"-\" * 90)\n",
        "    for row in sorted(table_data, key=lambda x: int(x[4].replace(',', '')), reverse=True):\n",
        "        print(f\"{row[0]:>4} | {row[1]:<40} | {row[2]:<8} | {row[3]:<10} | {row[4]:>10} | {row[5]:>6}\")\n",
        "    print(\"-\" * 90)\n",
        "    return table_data\n",
        "\n",
        "def visualize_hole_filling_results(original_fmb, filled_fmb, depth_map, fill_info):\n",
        "    H, W = original_fmb.shape\n",
        "    comparison = np.zeros((H * 2, W * 2, 3), dtype=np.uint8)\n",
        "    fmb_colors = {0: [220, 20, 60], 1: [46, 125, 50], 2: [30, 144, 255]}\n",
        "\n",
        "    original_colored = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for layer, color in fmb_colors.items():\n",
        "        original_colored[original_fmb == layer] = color\n",
        "    comparison[:H, :W] = original_colored\n",
        "\n",
        "    filled_colored = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for layer, color in fmb_colors.items():\n",
        "        filled_colored[filled_fmb == layer] = color\n",
        "    comparison[:H, W:] = filled_colored\n",
        "\n",
        "    changes = original_fmb != filled_fmb\n",
        "    change_vis = original_colored.copy()\n",
        "    change_vis[changes] = [255, 255, 0]\n",
        "    comparison[H:, :W] = change_vis\n",
        "\n",
        "    depth_normalized = ((depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255).astype(np.uint8)\n",
        "    depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_VIRIDIS)\n",
        "    comparison[H:, W:] = depth_colored\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(comparison, 'Original FMB', (10, 30), font, 1, (255, 255, 255), 2)\n",
        "    cv2.putText(comparison, 'After Hole Filling', (W + 10, 30), font, 1, (255, 255, 255), 2)\n",
        "    cv2.putText(comparison, 'Changes (Yellow)', (10, H + 30), font, 1, (255, 255, 255), 2)\n",
        "    cv2.putText(comparison, 'Depth Reference', (W + 10, H + 30), font, 1, (255, 255, 255), 2)\n",
        "\n",
        "    stats_text = f\"Filled: {fill_info['holes_filled']}, Preserved: {fill_info['holes_preserved']}\"\n",
        "    cv2.putText(comparison, stats_text, (10, H * 2 - 10), font, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    return comparison\n",
        "\n",
        "# ==================== Main Function ====================\n",
        "\n",
        "def main(enable_hole_filling=True):\n",
        "    \"\"\"Main function, executes complete intelligent FMB segmentation workflow\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Intelligent FMB Segmentation System\")\n",
        "    print(\"  Foreground-Middleground-Background Segmentation\")\n",
        "    print(\"  Version 2.1 (with Forced Semantic Rules)\")\n",
        "    print(\"  - Sky is ALWAYS Background (forced rule)\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"\\nPlease upload the following files:\")\n",
        "    print(\"1. Semantic segmentation image (semantic.png)\")\n",
        "    print(\"2. Depth map (depth.png)\")\n",
        "    print(\"3. JSON configuration file\")\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "    if IN_COLAB:\n",
        "        uploaded = files.upload()\n",
        "    else:\n",
        "        print(\"Please ensure files are in the current directory\")\n",
        "        uploaded = {}\n",
        "        import glob\n",
        "        png_files = glob.glob(\"*.png\")\n",
        "        json_files = glob.glob(\"*.json\")\n",
        "        for f in png_files + json_files:\n",
        "            uploaded[f] = None\n",
        "\n",
        "    semantic_path = None\n",
        "    depth_path = None\n",
        "    json_path = None\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        lower_name = filename.lower()\n",
        "        if 'semantic' in lower_name and lower_name.endswith('.png'):\n",
        "            semantic_path = filename\n",
        "        elif 'depth' in lower_name and lower_name.endswith('.png'):\n",
        "            depth_path = filename\n",
        "        elif lower_name.endswith('.json'):\n",
        "            json_path = filename\n",
        "\n",
        "    if semantic_path is None:\n",
        "        for filename in uploaded.keys():\n",
        "            if filename.lower().endswith('.png') and 'depth' not in filename.lower():\n",
        "                semantic_path = filename\n",
        "                break\n",
        "\n",
        "    if depth_path is None:\n",
        "        for filename in uploaded.keys():\n",
        "            if filename.lower().endswith('.png') and filename != semantic_path:\n",
        "                depth_path = filename\n",
        "                break\n",
        "\n",
        "    print(f\"\\nIdentified files:\")\n",
        "    print(f\"  Semantic: {semantic_path}\")\n",
        "    print(f\"  Depth: {depth_path}\")\n",
        "    print(f\"  JSON: {json_path}\")\n",
        "\n",
        "    if not all([semantic_path, depth_path, json_path]):\n",
        "        print(\"\\nError: Could not identify all required files!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nReading configuration...\")\n",
        "    color_to_idx, idx_to_info, openness, countability = read_config_from_json(json_path)\n",
        "    print(f\"  Loaded {len(color_to_idx)} semantic classes\")\n",
        "\n",
        "    print(\"\\nReading images...\")\n",
        "    semantic_img = cv2.imread(semantic_path)\n",
        "    semantic_img = cv2.cvtColor(semantic_img, cv2.COLOR_BGR2RGB)\n",
        "    depth_img = cv2.imread(depth_path, cv2.IMREAD_GRAYSCALE)\n",
        "    depth_map = depth_img.astype(np.float32)\n",
        "\n",
        "    H, W = depth_map.shape\n",
        "    print(f\"  Image size: {W}x{H}\")\n",
        "\n",
        "    print(\"\\nConverting semantic image...\")\n",
        "    semantic_map = semantic_rgb_to_idx_map(semantic_img, color_to_idx)\n",
        "\n",
        "    create_semantic_table(idx_to_info, semantic_map)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Starting FMB Segmentation...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    fmb_map, kmeans_original, adjustments, fmb_before_filling, fill_info = \\\n",
        "        process_fmb_segmentation_with_intelligent_system(\n",
        "            depth_map, semantic_map, openness, countability, idx_to_info,\n",
        "            enable_hole_filling=enable_hole_filling\n",
        "        )\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Generating visualizations...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    colored_kmeans = create_colored_fmb_map(kmeans_original)\n",
        "    colored_fmb = create_colored_fmb_map(fmb_map)\n",
        "    colored_semantic = visualize_semantic_with_original_colors(semantic_map, idx_to_info)\n",
        "    colored_objects, total_objects = visualize_closed_objects(semantic_map, openness)\n",
        "    adjustment_vis = visualize_adjustment_process(kmeans_original, fmb_map, semantic_map, openness)\n",
        "\n",
        "    if fmb_before_filling is not None:\n",
        "        colored_before_filling = create_colored_fmb_map(fmb_before_filling)\n",
        "        colored_after_filling = create_colored_fmb_map(fmb_map)\n",
        "\n",
        "    closed_semantic_colored = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for i in range(len(openness)):\n",
        "        if openness[i] == 1:\n",
        "            mask = semantic_map == i+1\n",
        "            if i+1 in idx_to_info:\n",
        "                closed_semantic_colored[mask] = idx_to_info[i+1]['rgb']\n",
        "\n",
        "    # Create visualization figure\n",
        "    fig = plt.figure(figsize=(24, 18))\n",
        "\n",
        "    ax1 = plt.subplot(3, 4, 1)\n",
        "    ax1.imshow(colored_semantic)\n",
        "    ax1.set_title('Semantic Segmentation (Original Colors)', fontsize=12)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2 = plt.subplot(3, 4, 2)\n",
        "    ax2.imshow(depth_map, cmap='viridis')\n",
        "    ax2.set_title('Depth Map (0=far, 255=near)', fontsize=12)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    ax3 = plt.subplot(3, 4, 3)\n",
        "    ax3.imshow(colored_objects)\n",
        "    ax3.set_title(f'Closed Objects ({total_objects} objects)', fontsize=12)\n",
        "    ax3.axis('off')\n",
        "\n",
        "    ax4 = plt.subplot(3, 4, 4)\n",
        "    ax4.imshow(closed_semantic_colored)\n",
        "    ax4.set_title('Closed Classes Only (Original Colors)', fontsize=12)\n",
        "    ax4.axis('off')\n",
        "\n",
        "    ax5 = plt.subplot(3, 4, 5)\n",
        "    ax5.imshow(colored_kmeans)\n",
        "    ax5.set_title('K-means Original', fontsize=12)\n",
        "    ax5.axis('off')\n",
        "\n",
        "    ax6 = plt.subplot(3, 4, 6)\n",
        "    ax6.imshow(colored_fmb)\n",
        "    ax6.set_title('After Intelligent Processing' + (' + Hole Filling' if enable_hole_filling else ''), fontsize=12)\n",
        "    ax6.axis('off')\n",
        "\n",
        "    ax7 = plt.subplot(3, 4, 7)\n",
        "    diff_map = np.zeros_like(colored_fmb)\n",
        "    diff_mask = kmeans_original != fmb_map\n",
        "    diff_map[~diff_mask] = colored_kmeans[~diff_mask] * 0.3\n",
        "    diff_map[diff_mask] = [255, 255, 0]\n",
        "    ax7.imshow(diff_map)\n",
        "    ax7.set_title('Changes (Yellow = Adjusted)', fontsize=12)\n",
        "    ax7.axis('off')\n",
        "\n",
        "    ax8 = plt.subplot(3, 4, 8)\n",
        "    ax8.imshow(adjustment_vis['adjusted_objects_map'])\n",
        "    ax8.set_title('Adjusted Objects Detail', fontsize=12)\n",
        "    ax8.axis('off')\n",
        "\n",
        "    ax9 = plt.subplot(3, 4, 9)\n",
        "    comparison = np.hstack([colored_kmeans[:, :W//2], colored_fmb[:, W//2:]])\n",
        "    ax9.imshow(comparison)\n",
        "    ax9.set_title('K-means (left) vs Final (right)', fontsize=12)\n",
        "    ax9.axis('off')\n",
        "\n",
        "    ax10 = plt.subplot(3, 4, 10)\n",
        "    overlay = colored_fmb.copy()\n",
        "    object_edges = ndimage.sobel(colored_objects.mean(axis=2)) > 0\n",
        "    overlay[object_edges] = [255, 255, 255]\n",
        "    ax10.imshow(overlay)\n",
        "    ax10.set_title('FMB + Object Boundaries', fontsize=12)\n",
        "    ax10.axis('off')\n",
        "\n",
        "    ax11 = plt.subplot(3, 4, 11)\n",
        "    adjustment_counts = {'Foreground': 0, 'Middleground': 0, 'Background': 0}\n",
        "    for info in adjustment_vis['object_info']:\n",
        "        to_name = ['Foreground', 'Middleground', 'Background'][info['to_layer']]\n",
        "        adjustment_counts[to_name] += 1\n",
        "    if any(adjustment_counts.values()):\n",
        "        bars = ax11.bar(adjustment_counts.keys(), adjustment_counts.values())\n",
        "        ax11.set_title('Objects Moved To Each Layer', fontsize=12)\n",
        "        ax11.set_ylabel('Number of Objects')\n",
        "    else:\n",
        "        ax11.text(0.5, 0.5, 'No Adjustments Made', ha='center', va='center', transform=ax11.transAxes)\n",
        "        ax11.set_title('Adjustment Statistics', fontsize=12)\n",
        "\n",
        "    ax12 = plt.subplot(3, 4, 12)\n",
        "    ax12.axis('off')\n",
        "    legend_elements = [\n",
        "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[220/255, 20/255, 60/255], markersize=10, label='Foreground (Near)'),\n",
        "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[46/255, 125/255, 50/255], markersize=10, label='Middleground'),\n",
        "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[30/255, 144/255, 255/255], markersize=10, label='Background (Far)'),\n",
        "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='yellow', markersize=10, label='Adjusted Pixels'),\n",
        "    ]\n",
        "    ax12.legend(handles=legend_elements, loc='center', fontsize=10)\n",
        "    ax12.set_title('Legend', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Hole filling visualization\n",
        "    if fmb_before_filling is not None and fill_info is not None:\n",
        "        fig_holes = plt.figure(figsize=(20, 10))\n",
        "\n",
        "        ax1 = plt.subplot(2, 3, 1)\n",
        "        ax1.imshow(create_colored_fmb_map(fmb_before_filling))\n",
        "        ax1.set_title('Before Hole Filling', fontsize=14)\n",
        "        ax1.axis('off')\n",
        "\n",
        "        ax2 = plt.subplot(2, 3, 2)\n",
        "        ax2.imshow(create_colored_fmb_map(fmb_map))\n",
        "        ax2.set_title('After Hole Filling', fontsize=14)\n",
        "        ax2.axis('off')\n",
        "\n",
        "        ax3 = plt.subplot(2, 3, 3)\n",
        "        changes_mask = fmb_before_filling != fmb_map\n",
        "        change_vis = create_colored_fmb_map(fmb_before_filling).copy()\n",
        "        change_vis[changes_mask] = [255, 255, 0]\n",
        "        ax3.imshow(change_vis)\n",
        "        ax3.set_title(f'Filled Holes (Yellow) - {fill_info[\"holes_filled\"]} holes', fontsize=14)\n",
        "        ax3.axis('off')\n",
        "\n",
        "        ax4 = plt.subplot(2, 3, 4)\n",
        "        ax4.imshow(depth_map, cmap='viridis')\n",
        "        ax4.set_title('Depth Map Reference', fontsize=14)\n",
        "        ax4.axis('off')\n",
        "\n",
        "        ax5 = plt.subplot(2, 3, 5)\n",
        "        labels = ['Holes Filled', 'Holes Preserved']\n",
        "        sizes = [fill_info['holes_filled'], fill_info['holes_preserved']]\n",
        "        if sum(sizes) > 0:\n",
        "            ax5.pie(sizes, labels=labels, autopct='%1.0f%%', startangle=90)\n",
        "        else:\n",
        "            ax5.text(0.5, 0.5, 'No holes detected', ha='center', va='center', transform=ax5.transAxes)\n",
        "        ax5.set_title('Hole Filling Statistics', fontsize=14)\n",
        "\n",
        "        ax6 = plt.subplot(2, 3, 6)\n",
        "        ax6.axis('off')\n",
        "        legend_text = f\"\"\"\n",
        "Hole Filling Summary:\n",
        "- Total holes detected: {fill_info['total_holes_detected']}\n",
        "- Holes filled: {fill_info['holes_filled']}\n",
        "- Holes preserved: {fill_info['holes_preserved']}\n",
        "\"\"\"\n",
        "        ax6.text(0.1, 0.5, legend_text, transform=ax6.transAxes, fontsize=12, verticalalignment='center', fontfamily='monospace')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\nFMB Distribution Statistics:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Layer':<15} {'K-means Original':>20} {'Final Result':>20}\")\n",
        "    print(\"-\" * 60)\n",
        "    total_pixels = fmb_map.size\n",
        "    for layer, layer_name in enumerate(['Foreground', 'Middleground', 'Background']):\n",
        "        kmeans_count = np.sum(kmeans_original == layer)\n",
        "        final_count = np.sum(fmb_map == layer)\n",
        "        kmeans_pct = (kmeans_count / total_pixels) * 100\n",
        "        final_pct = (final_count / total_pixels) * 100\n",
        "        print(f\"{layer_name:<15} {kmeans_count:>8,} ({kmeans_pct:>5.1f}%) {final_count:>8,} ({final_pct:>5.1f}%)\")\n",
        "    print(\"-\" * 60)\n",
        "    changed_pixels = np.sum(kmeans_original != fmb_map)\n",
        "    changed_pct = (changed_pixels / total_pixels) * 100\n",
        "    print(f\"\\nAdjusted pixels: {changed_pixels:,} ({changed_pct:.1f}%)\")\n",
        "\n",
        "    # Save results\n",
        "    cv2.imwrite('fmb_kmeans_original.png', cv2.cvtColor(colored_kmeans, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite('fmb_segmentation_final.png', cv2.cvtColor(colored_fmb, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite('closed_objects.png', cv2.cvtColor(colored_objects, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite('semantic_original_colors.png', cv2.cvtColor(colored_semantic, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite('closed_classes_original_colors.png', cv2.cvtColor(closed_semantic_colored, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    if adjustment_vis['adjusted_objects_map'] is not None:\n",
        "        cv2.imwrite('adjustment_visualization.png', cv2.cvtColor(adjustment_vis['adjusted_objects_map'], cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    print(f\"\\nResults saved:\")\n",
        "    print(f\"  - fmb_kmeans_original.png\")\n",
        "    print(f\"  - fmb_segmentation_final.png\")\n",
        "    print(f\"  - closed_objects.png\")\n",
        "    print(f\"  - semantic_original_colors.png\")\n",
        "    print(f\"  - closed_classes_original_colors.png\")\n",
        "    print(f\"  - adjustment_visualization.png\")\n",
        "\n",
        "    if fmb_before_filling is not None:\n",
        "        hole_comparison = visualize_hole_filling_results(fmb_before_filling, fmb_map, depth_map, fill_info)\n",
        "        cv2.imwrite('hole_filling_comparison.png', cv2.cvtColor(hole_comparison, cv2.COLOR_RGB2BGR))\n",
        "        print(f\"  - hole_filling_comparison.png\")\n",
        "\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            files.download('fmb_kmeans_original.png')\n",
        "            files.download('fmb_segmentation_final.png')\n",
        "            files.download('closed_objects.png')\n",
        "            files.download('adjustment_visualization.png')\n",
        "            files.download('semantic_original_colors.png')\n",
        "            files.download('closed_classes_original_colors.png')\n",
        "            if fmb_before_filling is not None:\n",
        "                files.download('hole_filling_comparison.png')\n",
        "            print(\"\\nProcessing complete! Files downloaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nProcessing complete! Files saved but download failed: {e}\")\n",
        "    else:\n",
        "        print(f\"\\nProcessing complete!\")\n",
        "\n",
        "# Entry point\n",
        "if __name__ == \"__main__\":\n",
        "    def in_notebook():\n",
        "        try:\n",
        "            from IPython import get_ipython\n",
        "            if 'IPKernelApp' in get_ipython().config:\n",
        "                return True\n",
        "        except:\n",
        "            pass\n",
        "        return False\n",
        "\n",
        "    enable_hole_filling = True\n",
        "\n",
        "    if not in_notebook():\n",
        "        import argparse\n",
        "        parser = argparse.ArgumentParser(description='Intelligent FMB Segmentation System')\n",
        "        parser.add_argument('--no-hole-filling', action='store_true', help='Disable hole filling')\n",
        "        args, _ = parser.parse_known_args()\n",
        "        enable_hole_filling = not args.no_hole_filling\n",
        "    else:\n",
        "        print(\"Running in Jupyter/Colab environment\")\n",
        "        print(f\"   Hole filling: {'Enabled' if enable_hole_filling else 'Disabled'}\")\n",
        "\n",
        "    print(\"Installing required libraries...\")\n",
        "    os.system('pip install pandas openpyxl scikit-learn scipy > /dev/null 2>&1')\n",
        "    print(\"Installation complete!\\n\")\n",
        "\n",
        "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "    main(enable_hole_filling=enable_hole_filling)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
